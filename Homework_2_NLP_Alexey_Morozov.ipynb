{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzgq6BYaoWZ8"
   },
   "source": [
    "# Homework: SMS Spam Classification\n",
    "\n",
    "**Course:** Deep Learning\n",
    "\n",
    "**Objective:** Train a model to classify SMS messages as spam or ham.\n",
    "\n",
    "**Dataset:** SMS Spam Collection  \n",
    "* **Source:** UCI ML Repository  \n",
    "* **Download:** https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection  \n",
    "* **Size:** ~5 500 messages (13 % spam, 87 % ham)  \n",
    "* **Format:** TSV with columns  \n",
    "  * `label`: “spam” (1) / “ham” (0)\n",
    "  * `text`: raw SMS content  \n",
    "\n",
    "**Tasks:**\n",
    "1. Load and explore the dataset.\n",
    "2. Preprocess the text.\n",
    "3. Define and train a model (any method from the course).\n",
    "4. Evaluate the model's performance using standard classification metrics on the test set.\n",
    "\n",
    "> **Success:** achieve ≥ 0.90 F1-score on the test set.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQwmsCShoYhT"
   },
   "source": [
    "# Prerequisites\n",
    "There might be pip errors, just ignore them, it's okay..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 13 10:46:09 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    25W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    25W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5KCB48fhoHar"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amorozov/.conda/envs/bert/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests, zipfile, io\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, roc_auc_score \n",
    "from transformers import BertTokenizerFast, BertTokenizer, BertModel, AutoModel, BertForSequenceClassification, Trainer, TrainingArguments, set_seed\n",
    "from datasets import Dataset\n",
    "\n",
    "# Dont change ssid for accurate testing results\n",
    "ssid = 42\n",
    "random.seed(ssid)\n",
    "np.random.seed(ssid)\n",
    "torch.manual_seed(ssid)\n",
    "torch.cuda.manual_seed_all(ssid)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "set_seed(ssid)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'Using device: {device}')\n",
    "\n",
    "def download_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "    response = requests.get(url)\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        z.extractall(\"data\")\n",
    "    df = pd.read_csv(\"data/SMSSpamCollection\", sep='\\t', header=None, names=['label', 'text'])\n",
    "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "    return df\n",
    "\n",
    "def train_val_test(df):\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=ssid)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=ssid)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKwdFr_Xpeac",
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Lm1MTfQcoj-p",
    "outputId": "1c9cac41-3ef9-4d07-e70c-5204f58ebe9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n",
      "5      1  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      0  Even my brother is not like to speak with me. ...\n",
      "7      0  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8      1  WINNER!! As a valued network customer you have...\n",
      "9      1  Had your mobile 11 months or more? U R entitle...\n"
     ]
    }
   ],
   "source": [
    "df = download_data()\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "large = 14; med = 10; small = 6\n",
    "params = {'axes.titlesize': med,\n",
    "          'legend.fontsize': small,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'xtick.labelsize': small,\n",
    "          'ytick.labelsize': small,\n",
    "          'figure.titlesize': large,\n",
    "          'axes.grid': True,\n",
    "          'grid.alpha': 0.8,}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    '''\n",
    "    Cleans text into a basic form:\n",
    "    1. Remove numbers and special charecters (&, #, etc.)\n",
    "    2. Remove extra spaces\n",
    "    3. Remove RT in case of Re-Tweets\n",
    "    5. Remove embedded URL links\n",
    "    6. Remove HTML tags\n",
    "    7. Remove emojis\n",
    "    8. Make all text lowercase\n",
    "    \n",
    "    text - Text piece to be cleaned.\n",
    "    '''\n",
    "    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n",
    "    text = template.sub(r'', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n",
    "    only_text = soup.get_text()\n",
    "    text = only_text\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\d\\s]\", \" \", text) #Remove special Charecters\n",
    "    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n",
    "    text = re.sub(r\"RT \", \" \", text) #Remove RT for Re-tweets\n",
    "    text = re.sub(r\"[0-9]\", \" \", text) #Remove Numbers\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def simple_text_cleaning(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing text: 100%|██████████| 5572/5572 [00:00<00:00, 103701.38it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Preprocessing text\")\n",
    "df['text'] = df['text'].progress_apply(simple_text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = train_val_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_plot = df.copy()\n",
    "df_plot['lengths'] = [len(x.split()) for x in df_plot.text.values]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "sns.kdeplot(data=df_plot, x='lengths', fill=True, color='#97d700', alpha=.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57743559 3.72848948]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(train_df.label.values), \n",
    "    y=train_df.label.values\n",
    ")\n",
    "print(class_weights)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DAuA39WuIS7",
    "tags": []
   },
   "source": [
    "# Your training code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4p_zE3T0vNmD"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'checkpoint': 'bert-base-uncased',\n",
    "    'class_weights': weights,\n",
    "    'output_logits': 768,\n",
    "    'max_len': 25,\n",
    "    'batch_size': 64,\n",
    "    'dropout': 0.1,\n",
    "    'num_workers': 2,\n",
    "    'epochs': 10,\n",
    "    'lr': 2e-5,\n",
    "    'scheduler_name': 'ReduceLROnPlateau',\n",
    "    'max_lr': 5e-3,                 # OneCycleLR\n",
    "    'pct_start': 0.3,               # OneCycleLR\n",
    "    'anneal_strategy': 'cos',       # OneCycleLR\n",
    "    'div_factor': 1e3,              # OneCycleLR\n",
    "    'final_div_factor': 1e3,        # OneCycleLR\n",
    "    'T_0': 3,                      # CosineAnnealingWarmRestarts\n",
    "    'min_lr': 1e-5,                 # CosineAnnealingWarmRestarts   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset:\n",
    "    def __init__(self, texts, labels, max_len=params['max_len'], checkpoint=params['checkpoint']):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "        self.num_examples = len(self.texts)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_examples\n",
    "\n",
    "    def tokenize(self):\n",
    "        \n",
    "        tokens = self.tokenizer.batch_encode_plus(\n",
    "            self.texts.tolist(),\n",
    "            max_length = self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "            )\n",
    "        \n",
    "        ids = torch.tensor(tokens['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(tokens['attention_mask'], dtype=torch.long)\n",
    "        labels = torch.tensor(self.labels.tolist(), dtype=torch.long)\n",
    "\n",
    "        return TensorDataset(ids, mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, scheduler_params=params):\n",
    "    if scheduler_params['scheduler_name'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=scheduler_params['T_0'],\n",
    "            eta_min=scheduler_params['min_lr'],\n",
    "            last_epoch=-1\n",
    "            )\n",
    "    elif scheduler_params['scheduler_name'] == 'OneCycleLR':\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=scheduler_params['max_lr'],\n",
    "            steps_per_epoch=int(train_df.shape[0] / params['batch_size']) + 1,\n",
    "            epochs=scheduler_params['epochs'],\n",
    "            pct_start=scheduler_params['pct_start'],\n",
    "            anneal_strategy=scheduler_params['anneal_strategy'],\n",
    "            div_factor=scheduler_params['div_factor'],\n",
    "            final_div_factor=scheduler_params['final_div_factor'],\n",
    "            )\n",
    "    elif scheduler_params['scheduler_name'] == 'ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.1, \n",
    "            patience=10, \n",
    "            threshold=0.0001, \n",
    "            threshold_mode='rel', \n",
    "            cooldown=0, \n",
    "            min_lr=0, \n",
    "            eps=1e-08\n",
    "            )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDetector(nn.Module):\n",
    "    def __init__(self, checkpoint=params['checkpoint'], params=params):\n",
    "        super(SpamDetector, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(checkpoint, return_dict=False)\n",
    "        self.dropout = nn.Dropout(params['dropout'])\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids, attention_mask)\n",
    "        pooled_output = self.fc1(pooled_output)\n",
    "        pooled_output = self.relu(pooled_output)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc2(pooled_output)\n",
    "        # output = self.softmax(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usr_f1_score(output, target):\n",
    "    y_pred = torch.argmax(output, dim=1).cpu().numpy()\n",
    "    target = target.cpu()\n",
    "    return f1_score(target, y_pred, average='binary') \n",
    "\n",
    "def usr_roc_score(output, target):\n",
    "    try:\n",
    "        probs = torch.softmax(output, dim=1)[:, 1].cpu().detach().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        return roc_auc_score(target, probs)\n",
    "    except:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_dataset, valid_dataset, params=params, epochs=params['epochs'], scheduler=params['scheduler_name']):\n",
    "    model.to(device)\n",
    "    weights = params['class_weights'].to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['lr'])\n",
    "    clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "  \n",
    "    if scheduler is not None:\n",
    "        scheduler = get_scheduler(optimizer)\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_f1 = 0\n",
    "        train_roc = 0\n",
    "        stream_1 = tqdm(train_dataset)\n",
    "        stream_1.set_description('Training')\n",
    "        for batch in stream_1:\n",
    "            optimizer.zero_grad()\n",
    "            batch = [r.to(device) for r in batch]\n",
    "            ids, mask, target = batch\n",
    "            logits = model(ids, mask)\n",
    "            loss = criterion(logits, target)\n",
    "            f1_score = usr_f1_score(logits, target)\n",
    "            roc_score = usr_roc_score(logits, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler and params['scheduler_name'] != 'ReduceLROnPlateau':  # Step here only for non-plateau\n",
    "                scheduler.step()\n",
    "            train_loss += loss.item() * ids.size(0)\n",
    "            train_f1 += f1_score\n",
    "            train_roc += roc_score\n",
    "            stream_1.update(1)\n",
    "    \n",
    "        train_loss/= len(train_dataset)\n",
    "        train_f1 /= len(train_dataset)\n",
    "        train_roc /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_f1 = 0\n",
    "        valid_roc = 0\n",
    "        stream_2 = tqdm(valid_dataset)\n",
    "        stream_2.set_description('Validating')\n",
    "        for batch in stream_2:\n",
    "            batch = [r.to(device) for r in batch]\n",
    "            ids, mask, target = batch\n",
    "            logits = model(ids, mask)\n",
    "            loss = criterion(logits, target)\n",
    "            f1_score = usr_f1_score(logits, target)\n",
    "            roc_score = usr_roc_score(logits, target)\n",
    "            valid_loss += loss.item() * ids.size(0)\n",
    "            valid_f1 += f1_score\n",
    "            valid_roc += roc_score\n",
    "            stream_2.update(1)\n",
    "\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        valid_f1 /= len(valid_dataset)\n",
    "        valid_roc /= len(valid_dataset)\n",
    "        \n",
    "        # Step ReduceLROnPlateau after validation\n",
    "        if scheduler and params['scheduler_name'] == 'ReduceLROnPlateau':\n",
    "            scheduler.step(valid_loss)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "        print(f\"Epoch: {epoch+1:02}/{epochs:02}. Train Loss: {train_loss:.3f}. Validation Loss: {valid_loss:.3f}\")\n",
    "        print(f\"Epoch: {epoch+1:02}/{epochs:02}. Train F1: {train_f1:.3f}. Validation F1: {valid_f1:.3f}\")\n",
    "        print(f\"Epoch: {epoch+1:02}/{epochs:02}. Train ROC: {train_roc:.3f}. Validation ROC: {valid_roc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amorozov/.conda/envs/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning:\n",
      "\n",
      "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BERTDataset(\n",
    "    train_df.text.values,\n",
    "    train_df.label.values\n",
    ").tokenize()\n",
    "\n",
    "val_dataset = BERTDataset(\n",
    "    val_df.text.values,\n",
    "    val_df.label.values\n",
    ").tokenize()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=params['batch_size'], \n",
    "    sampler=RandomSampler(train_dataset), \n",
    "    #shuffle=True,\n",
    "    num_workers=params['num_workers'], \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=params['batch_size'], \n",
    "    sampler=SequentialSampler(val_dataset), \n",
    "    #shuffle=False,\n",
    "    num_workers=params['num_workers'], \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:  11%|█▏        | 7/61 [00:00<00:04, 12.96it/s]/home/amorozov/.conda/envs/bert/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning:\n",
      "\n",
      "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "Training: : 77it [00:05, 14.27it/s]                      \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.96it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01/10. Train Loss: 21.255. Validation Loss: 8.062\n",
      "Epoch: 01/10. Train F1: 0.779. Validation F1: 0.914\n",
      "Epoch: 01/10. Train ROC: nan. Validation ROC: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: : 78it [00:06, 14.19it/s]                      To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.71it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 41.15it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02/10. Train Loss: 5.371. Validation Loss: 5.794\n",
      "Epoch: 02/10. Train F1: 0.938. Validation F1: 0.917\n",
      "Epoch: 02/10. Train ROC: 0.994. Validation ROC: 0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.72it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 40.30it/s]                      To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:01<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03/10. Train Loss: 2.775. Validation Loss: 9.441\n",
      "Epoch: 03/10. Train F1: 0.970. Validation F1: 0.940\n",
      "Epoch: 03/10. Train ROC: 0.999. Validation ROC: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.78it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 40.92it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04/10. Train Loss: 0.797. Validation Loss: 8.369\n",
      "Epoch: 04/10. Train F1: 0.993. Validation F1: 0.940\n",
      "Epoch: 04/10. Train ROC: 1.000. Validation ROC: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.73it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:01<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05/10. Train Loss: 1.485. Validation Loss: 9.344\n",
      "Epoch: 05/10. Train F1: 0.971. Validation F1: 0.938\n",
      "Epoch: 05/10. Train ROC: 1.000. Validation ROC: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: : 77it [00:06, 14.33it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.76it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 41.01it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:01<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06/10. Train Loss: 0.387. Validation Loss: 9.147\n",
      "Epoch: 06/10. Train F1: 0.995. Validation F1: 0.945\n",
      "Epoch: 06/10. Train ROC: 1.000. Validation ROC: 0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: : 78it [00:06, 14.37it/s]                      \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.74it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 40.99it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07/10. Train Loss: 0.140. Validation Loss: 11.512\n",
      "Epoch: 07/10. Train F1: 0.999. Validation F1: 0.949\n",
      "Epoch: 07/10. Train ROC: 1.000. Validation ROC: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: : 78it [00:06, 14.61it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.87it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08/10. Train Loss: 0.078. Validation Loss: 11.917\n",
      "Epoch: 08/10. Train F1: 1.000. Validation F1: 0.949\n",
      "Epoch: 08/10. Train ROC: 1.000. Validation ROC: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: : 78it [00:06, 14.34it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.69it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 41.16it/s]                      TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09/10. Train Loss: 0.648. Validation Loss: 10.617\n",
      "Epoch: 09/10. Train F1: 0.989. Validation F1: 0.952\n",
      "Epoch: 09/10. Train ROC: 1.000. Validation ROC: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training:   0%|          | 0/61 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Training: 100%|██████████| 61/61 [00:06<00:00,  9.82it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating:   0%|          | 0/14 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: : 23it [00:00, 42.22it/s]                      \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Validating: 100%|██████████| 14/14 [00:00<00:00, 14.49it/s]\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10. Train Loss: 0.455. Validation Loss: 7.803\n",
      "Epoch: 10/10. Train F1: 0.989. Validation F1: 0.961\n",
      "Epoch: 10/10. Train ROC: 1.000. Validation ROC: 0.984\n"
     ]
    }
   ],
   "source": [
    "model = SpamDetector()\n",
    "train(model, device, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXi_SgxCuM3g"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "J25A2P5Un5Fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amorozov/.conda/envs/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning:\n",
      "\n",
      "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test —     acc: 0.974, prec: 0.846, rec: 0.982, f1: 0.909\n"
     ]
    }
   ],
   "source": [
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "tokenizer = BertTokenizerFast.from_pretrained(params['checkpoint'])\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_df.text.tolist(),\n",
    "    max_length = params['max_len'],\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "test_ids = torch.tensor(tokens_test['input_ids'], dtype=torch.long)\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'], dtype=torch.long)\n",
    "test_labels = torch.tensor(test_df.label.to_list(), dtype=torch.float)\n",
    "\n",
    "# Get raw logits from model\n",
    "logits = model(test_ids.to(device), test_mask.to(device))\n",
    "\n",
    "y_pred_probs = torch.softmax(logits, dim=1).cpu().detach().numpy()\n",
    "y_pred_test = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "test_labels_np = test_labels.cpu().numpy().astype(int)\n",
    "\n",
    "acc, prec, rec, f1 = accuracy_score(test_labels_np, y_pred_test), *precision_recall_fscore_support(test_labels_np, y_pred_test, average='binary')[:3]\n",
    "print(\"\\nTest —     acc: {:.3f}, prec: {:.3f}, rec: {:.3f}, f1: {:.3f}\".format(\n",
    "    acc, prec, rec, f1\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "JQwmsCShoYhT"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bert]",
   "language": "python",
   "name": "conda-env-.conda-bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
